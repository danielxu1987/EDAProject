---
title: "EDA Project"
output:
  html_document: default
---

This is the R Notebook for the project from Sifeng Xu, 24525844 for unit *CITS4009 Computation Data Analysis*. It demonstrates the process and findings of EDA based on the **Countries and Death Causes** dataset. 

```{r setup, echo=FALSE}
# Load  libraries
# library(shiny)
# library(shinyWidgets)
library(ggplot2)
library(gridExtra)
library(knitr)
library(dplyr)


# load dataset
df_original <- read.csv("./Countries and death causes.csv",header = T, sep=",")

df <- df_original

dietVars <- c('Diet.low.in.whole.grains', 'Diet.low.in.fruits', 'Diet.low.in.Vegetables', 'Diet.low.in.nuts.and.seeds', 'Diet.high.in.sodium')

dietTargetVar <- c('Diet.high.in.sodium')
dietFeatureVars <- dietVars[dietVars != dietTargetVar]

count_nas <- function(data){
  count_missing <- function(data){
    sapply(data, FUN=function(col) sum(is.na(col)))
  }
  nacounts <- count_missing(data)
  hasNA = which(nacounts > 0)
  nacounts[hasNA]
}

count_null <- function(data){
  count_missing <- function(data){
    sapply(data, FUN=function(col) sum(col == ''))
  }
  nullcounts <- count_missing(data)
  hasNull = which(nullcounts > 0)
  nullcounts[hasNull]
}

count_negative <- function(data){
  count_missing <- function(data){
    sapply(data, FUN=function(col) sum(col < 0))
  }
  negcounts <- count_missing(data)
  hasNegative = which(negcounts > 0)
  negcounts[hasNegative]
}

dataUK <- df[df['Entity']=='United Kingdom',] #df[df['Entity']=='China',]
dataTAN <- df[df['Entity']=='Tanzania',]
dataNLD <- df[df['Entity']=='Netherlands',]
dataCAM <- df[df['Entity']=='Cambodia',]

```

### Basic information of the data


```{r glance, echo=TRUE}

data.frame(
  columeID = col(df)[1,],
  variables = names(df),
  class = sapply(df, typeof),
  first_values = sapply(df, function(x) paste0(head(x), collapse = ', ')),
  row.names = NULL) |>
kable()

summary(df) |> kable()

head(df) |> kable()

```


A first glance of data shows 31 columns which consists of 3 non-numerical data:

* countries' full name
* short country code
* year of measurements (1990-2019) 

the rest is numerical data showing how many deaths from each cause, each year and each country/region. Some countries are counted together such as *G20, OECD Countries, South-East Asia Region* and *Western Passific Region*. Also, some measured variables look similar such as *Outdoor.air.pollution, Household.air.pollution.from.solid.fuels* and *Air.pollution*.  


To give an impression what the dataset looks like, a snippet shows 6 countries and their deaths count from several causes in 2010.

```{r snippet, include=TRUE}
df_2010 <- df[df['Year']==2010, 
  c('Entity', 'Code', 'Outdoor.air.pollution','Child.wasting', 'Smoking', 'Drug.use')]
countries <- c('Afghanistan', 'Morocco', 'Nigeria', 'Australia', 'Belgium', 'Congo')
snippet <- subset(df_2010, Entity %in% countries)
names(snippet)[1] <- 'Country'
print(snippet)
```


### Histogram for single death cause

First check the data range by histogram. Variables that are linked to environment such as outdoor and household air quality tend to cause more deaths. This may prove that the long-term influence of poor air quality, which often sustains through a longer period, can kill many people living in that area/region.

![Outdoor air pollution](./images/hist_single_oap.JPG)
![Household air pollution from solid fuels](./images/hist_single_hap.JPG)

In contrast, causes such as *iron deficiency* and *vitamin A deficiency* lead to far less mortalities worldwide. Probably lack of iron or vitamin A alone is not too critical to the survival of most people.

![Iron deficiency](./images/hist_single_iron.JPG)
![Vitamin A deficiency](./images/hist_single_va.JPG)

Across all variables, a fact is that high value of mortality does not appear often as most values seem to stay close to the lower boundary. Note a spike near zero for all example figures.

### Boxplot single

After comparing different countries with boxplot, it is noticeable that developed countries usually have less mortalities than developing countries in causes related to poor hygiene (e.g. water quality, unsafe sanitation and no access to hand washing facility). 

![Compare countries - unsafe water source](./images/box_water.JPG)

![Compare countries - unsafe sanitation](./images/box_sani.JPG)

![Compare countries - no access to handwashing facility](./images/box_handw.JPG)

Two pairs of countries are selected here as examples between the *Uk* and *Tanzania*, as well as the *Netherlands* and *Cambodia*. The reason why they are compared to each other is because counties in each pair shares similar population according to [Worldometers](https://www.worldometers.info/world-population/population-by-country/).

### Trend comparison

Line graph shows the trend of certain causes from 1990 to 2019. Comparison between countries shows interesting facts.  Alcohol use seems to be more detrimental to people's health in recent years in both developed and developing countries selected in previous section. 

![](./images/trend_alco.JPG)

On the other hand, outdoor air pollution appears to become less harmful in western Europe than in Africa or Asia. This may have to do with the progress of industrialisation which leads to air pollution. In other words, Europe was almost at the end of it around the turn of the century, and they paid more attention to the environmental impact. While certain areas in Africa and Asia just started to industrialize themselves. That is why the air quality got worse and worse in this period there.

![](./images/trend_oap.JPG)

### Bar chart

Drug use seems to have serious impact in both rich and poor areas. In the figure below, far more people ended their life in India and the USA due to drug use than the whole African Region in 2010. European region is not much better as they ranked the third in this set of comparison worldwide.

![](./images/Bar_compare_us.JPG)

### Correlation between variables

When comparing multiple variables, it is clear that diet related death causes are  positive linear for African region. This may indicate the food security issue in this area.  On the other hand, this correlation seems less obvious for North America where the general public have much more dietary options.

![](./images/pair_diet_afr.JPG)

![](./images/pair_diet_northa.JPG)

Smooth curve and jittering points shows drug use and unsafe sex clustering when sex fatality value is low.  Once the value grows further they seemed less correlated.

![](./images/smooth_sexdrug_lim.JPG)

### Missing values and anomolies

These values are checked in all numerical variables: *NA, null, zeros* and *negative numbers*. 

```{r nas, echo=TRUE} 

numericVars <- names(df[, -c(1:3)]) # ignore Entity, Code and Year columns
df_num <- df[numericVars]

print(sum(is.na(df_num)))

print(sum(is.null(df_num)))

print(sum(df_num < 0))

print(sum(df_num == 0))
```

Currently there is no NA's in the dataset, neither are there any negative values. There are zero values, which may indicate that either no one died of that specific cause in a country in a specific year, or they were missing values. Although it is possible to treat zero's as missing values and replace them with e.g. median or mean, doing this will overwrite all the zero's which are truly reflecting zero mortality.  Therefore, in this exploration attempt we will keep zero's as-is.

When checking the first three columns it shows that *Code* are empty in 690 rows. These appear to be specific to aggregated regions e.g. OECD Countries, or regions within a country without a valid country code e.g. Scotland.

```{r rm_code, echo=TRUE}

count_empty <- function(data){
  count_missing <- function(data){
    sapply(data, FUN=function(col) sum(col == ''))
  }
  nullcounts <- count_missing(data)
  hasNull = which(nullcounts > 0)
  nullcounts[hasNull]
}

print(count_empty(df))
empty_rows <- df[df$Code == '', ]
print(empty_rows[sample(nrow(empty_rows), size = 6, replace = F), c(1:6)])
```

Since the Entity variable has no missing value and shows clear label of the region/country, we think it is safe to drop the *Code* column for a cleaner dataset. Also to make it easier to understand Entity is converted to Country.

```{r rmcode}
df$Code <- NULL
df$Country <- df$Entity
df$Entity <- NULL
```

### Classfication 

We would like to know more about the death cause that have large impact worldwide. Since the absolute number of mortality can vary largely depending on the population of a country, a better measurement is the percentage of each death cause, with respect to the total casualties in that row. 

We will first create a rate to count the percentage of each specific casualty cause. Then visualise the stats with boxplot to see the major players worldwide. Also country and year will be converted to factor.

```{r addCat, echo=TRUE}

df$Country <- as.factor(df$Country)
df$Year <- as.factor(df$Year)

df$total.mortality <- rowSums(df[numericVars])

for (col in numericVars) {
    df[paste0(col, ".rate")] <- df[col] / df['total.mortality']
}

rateVars <- grep("\\.rate$", names(df), value = TRUE)

figRateAll <- ggplot(stack(df[rateVars])) + geom_boxplot(mapping = aes(x = ind, y = values)) + labs(x ='', y='Weight in total mortality') + coord_flip() 

print(figRateAll)

```

### Single variable prediction
It seems high blood pressure, smoking, high glucose rate and high BMI (obesity) are the top reasons to people's death. Now we would like to see when smoking kills more than obesity.  So we will first generate an outcome column which indicates if smoking kills more than obesity does (binary value). This variable holds the ground truth to check against the prediction later. The country and year will be the categorical variables to evaluate in the single variable selection process.

Now it is time to separate the data into training (81%), calibration(9%) and test (10%) data.

```{r get_train_cal_test, echo=TRUE}

outcome <- c('Smoking.kills.more') # sodium.over.median
pos <- TRUE # positive value 

df <- df |>
  mutate(
    Smoking.kills.more = (Smoking > High.body.mass.index)
)

d <- df

set.seed(729375)
d$rgroup <- runif(dim(d)[1])
dTrainAll <- subset(d, rgroup<=0.9)
dTest <- subset(d, rgroup>0.9)

# split dTrainAll into a training set and a validation (or calibration) set
useForCal <- rbinom(n=dim(dTrainAll)[1], size=1, prob=0.1)>0
dCal <- subset(dTrainAll, useForCal)
dTrain <- subset(dTrainAll, !useForCal)

print(dim(dTrain))

print(dim(dCal))

print(dim(dTest))

```

The next step is to go through the categorical variables and see which one has the best prediction chance. Here the null model is saying the prediction will be the overall proportion of True values, regardless what input it receives. Therefore, anything that is selected should help predict the result better than this model does. 

```{r catVars_compare, echo=TRUE, warning=FALSE}

# names of columns that are categorical type and numerical type
vars <- setdiff(colnames(dTrainAll), c(outcome, 'rgroup'))
catVars <- vars[sapply(df[,vars], class) %in% c('character', 'logical',  'factor')]

mkPredC <- function(outCol, varCol, appCol) {
  pPos <- sum(outCol==pos)/length(outCol)
  naTab <- table(as.factor(outCol[is.na(varCol)]))
  pPosWna <- (naTab/sum(naTab))[pos]
  vTab <- table(as.factor(outCol), varCol)
  pPosWv <- (vTab[pos,]+1.0e-3*pPos)/(colSums(vTab)+1.0e-3)
  pred <- pPosWv[appCol]
  pred[is.na(appCol)] <- pPosWna
  pred[is.na(pred)] <- pPos
  pred
}

# now go through all the categorical variables in the `catVars` vector
# and perform the predictions. 
for (v in catVars) {
  pi <- paste('pred.', v, sep='')
  dTrain[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dTrain[,v])
  dCal[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dCal[,v])
  dTest[,pi] <- mkPredC(dTrain[,outcome], dTrain[,v], dTest[,v])
}

# Define a function to compute log likelihood so that we can reuse it.
logLikelihood <- function(ypred, ytrue) {
  sum(ifelse(ytrue, log(ypred), log(1-ypred)), na.rm=T)
}

# Compute the likelihood of the Null model on the calibration
pred.Null <- sum(dTrain[,outcome]==pos)/nrow(dTrain)
cat("Proportion of outcome == True in dTrain:", pred.Null)

logNull <- logLikelihood(sum(dCal[,outcome]==pos)/nrow(dCal), dCal[,outcome]==pos)
cat("The log likelihood of the Null model is:", logNull)

selCatVars <- c()

for (v in catVars) {
  pi <- paste('pred.', v, sep='')
  logPred <- logLikelihood(dCal[,pi], dCal[,outcome]==pos)
  cat(sprintf("%6s, log likelihood: %g\n", v, logPred))
  devDrop <- 2*(logPred - logNull)
  
  cat(sprintf("%6s, deviance reduction: %g\n", v, devDrop))
  selCatVars <- c(selCatVars, pi)
}

devDrop <- 2*(logLikelihood(dCal[,outcome], dCal[,outcome]==pos) - logNull)
cat(sprintf("To compare, deviance reduction of the truth for %6s is: %g\n", outcome, devDrop))

```

The log likelihood and deviance reduction do not look great in either country or year. Let is check how they perform in the ROC curve.

```{r roc_curve, echo=TRUE}
library(ROCit)

# colour_id 1-7 are: black,red,green,blue,cyan,purple,gold
plot_roc <- function(predcol, outcol, colour_id=2, overlaid=F) {
  ROCit_obj <- rocit(score=predcol, class=outcol==pos)
  par(new=overlaid)
  plot(ROCit_obj, col = c(colour_id, 1),
  legend = FALSE, YIndex = FALSE, values = FALSE)
}

plot_roc(dCal$pred.Year, dCal[,outcome]) #Year is red
plot_roc(dCal$pred.Country, dCal[,outcome], colour_id=3, overlaid=T) # Country is green
```

Country seems to help more than Year since its AUC value is always higher than the null model. Now we are going to use all numerical variables for prediction and see which one performs the best to predict `r outcome`.

```{r selnumVar, echo=TRUE, warning=FALSE}
numericVars <- vars[sapply(df[,vars], class) %in% c('numeric','integer')]

# get all percentage / rate variables 
rateVars <- grep("\\.rate$", numericVars, value = TRUE)

mkPredN <- function(outCol, varCol, appCol) {
  cuts <- unique(as.numeric(
    quantile(varCol, probs=seq(0, 1, 0.1), na.rm=T)))
  varC <- cut(varCol, cuts)
  appC <- cut(appCol, cuts)
  mkPredC(outCol, varC, appC)
}

# now go through all numerical variables in the `numericVars` vector and perform the predictions.
for (v in numericVars) {
  pi <- paste('pred.', v, sep='')
  dTrain[,pi] <- mkPredN(dTrain[,outcome], dTrain[,v], dTrain[,v])
  dTest[,pi] <- mkPredN(dTrain[,outcome], dTrain[,v], dTest[,v])
  dCal[,pi] <- mkPredN(dTrain[,outcome], dTrain[,v], dCal[,v])
}

# selNumVars is a vector that keeps the names of the top performing numerical variables.
selNumVars <- c()
minDrop <- -100

for (v in numericVars) {
  pi <- paste('pred.', v, sep='')
  logPred <- logLikelihood(dCal[,pi], dCal[,outcome]==pos)
  
  devDrop <- 2*(logPred - logNull)
  if (devDrop >= minDrop) {
    cat(sprintf("%6s, deviance reduction: %g\n", v, devDrop))
    selNumVars <- c(selNumVars, pi)
  }
}

```

Now that both types of variables are shortlisted, let us see how it performs using AUC in calibration and test dataset. Also check the result with 100 fold cross-validation.

```{r evaluate, echo=TRUE}
library(ROCR)
calcAUC <- function(ypred, ytrue) {
  perf <- performance(prediction(ypred, ytrue), 'auc')
  as.numeric(perf@y.values)
}

selVars <- c()

## Performance of the top performing single variables on the test set:
for(v in c(selCatVars, selNumVars)) {
  pi <- v
  aucTrain <- calcAUC(dTrain[,pi], dTrain[,outcome])
  if (aucTrain > 0.53) {
    selVars <- c(selVars, pi)
    aucCal <- calcAUC(dCal[,pi], dCal[,outcome])
    print(sprintf(
      "%s: trainAUC: %4.3f; calibrationAUC: %4.3f",
      pi, aucTrain, aucCal))
  } 
}

# Run 100-fold cross validation
vars <- c('Country', 'Unsafe.water.source', 'Diet.low.in.nuts.and.seeds', 'Household.air.pollution.from.solid.fuels', 'No.access.to.handwashing.facility', 'Child.stunting', 'Iron.deficiency')


for (var in vars) {
  aucs <- rep(0,100)
  for (rep in 1:length(aucs)) {
    useForCalRep <- rbinom(n=nrow(dTrainAll), size=1, prob=0.1) > 0
    predRep <- mkPredC(dTrainAll[!useForCalRep, outcome],
    dTrainAll[!useForCalRep, var],
    dTrainAll[useForCalRep, var])
    aucs[rep] <- calcAUC(predRep, dTrainAll[useForCalRep, outcome])
  }
  print(sprintf("%s: mean: %4.3f; sd: %4.3f", var, mean(aucs), sd(aucs)))
  if(mean(aucs) > 0.5){
    
  }
}

print(selVars)

```

AFter inspecting the best performing variables a bit more, *Country* still seems a good relevant feature variable. *Unsafe.water.source* and *Household.air.pollution.from.solid.fuels* barely predict better than 50% with a high standard deviation that makes its performance low. 

Strange prediction for Country can be > 1.0??

```{r double_density_cat, include=FALSE}

# outliers <- dCal[dCal$pred.Entity > 1.0, c('Entity', 'Year', 'pred.Entity', 'Smoking.kills.more', 'Smoking', 'High.body.mass.index', 'Smoking.rate', 'High.body.mass.index.rate')]
# print(outliers)

fig1 <- ggplot(dCal) + geom_density(aes(x=pred.Country, color=as.factor(Smoking.kills.more)))

fig2 <- ggplot(dCal) + geom_density(aes(x=pred.Diet.low.in.nuts.and.seeds.rate, color=as.factor(Smoking.kills.more)))

grid.arrange(fig1, fig2, ncol=1)

```

Check the ROC curve for all 3 variables.

```{r}
plot_roc(dCal$pred.Unsafe.water.source, dCal[,outcome], colour_id=7) #Water source is gold
plot_roc(dCal$pred.Country, dCal[,outcome], colour_id=3, overlaid=T) # Country is green
plot_roc(dCal$pred.Household.air.pollution.from.solid.fuels, dCal[,outcome], colour_id=4, overlaid=T) # household air pollution is blue
```
*Country* still appears to be the best performer, with *Unsafe.water.source* being the second best and *Household.air.pollution.from.solid.fuels* being the last which predicts less than the null model around $1-Specificity = 0.8$. This means whether or not smoking kills more people than obesity is a country specific issue. We will take these 3 feature variables into the multiple feature model to see if they all together can do a better job. 


## Decision tree model

## Naive Bayers model

## LIME evaluation 

## Clustering